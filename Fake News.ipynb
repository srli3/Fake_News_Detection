{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INLS 613: Fake News Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "\n",
    "1. Import Data\n",
    "2. Extract Features\n",
    "3. Split Train and Test\n",
    "4. Train Models\n",
    "5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fake_or_real_news.csv/fake_or_real_news.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAKE', 'REAL'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'title', 'text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1: Convert Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing ### Importing a preprocessor to convert the labels in the target class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_class_y= [ 'FAKE', 'REAL']\n",
    "le= preprocessing.LabelEncoder()\n",
    "le.fit(data_class_y)\n",
    "#y should now be an array of labels where 0 is FAKE and 1 is REAL\n",
    "y=le.transform(df['label']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2: Downcase text and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lower takes in an array of strings and converts every string to all lower case\n",
    "def lower(arr):\n",
    "    out=[]\n",
    "    for i in range(len(arr)):\n",
    "        out.append(arr[i].lower())\n",
    "    return out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_text=lower(df['text'])\n",
    "lower_title=lower(df['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3: Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def remove_stops(s):\n",
    "    word_list = s.split(\" \");\n",
    "    filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def remove_all_stops(a):\n",
    "    out=[]\n",
    "    for i in range(len(a)):\n",
    "        out.append(remove_stops(a[i]))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_no_stops= remove_all_stops(lower_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Convert and Combine Title and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_convert(s):\n",
    "    words = s.split(\" \");\n",
    "    for i in range(len(words)):\n",
    "        words[i]=\"title_\"+words[i]\n",
    "    return \" \".join(words)\n",
    "\n",
    "def mult_title_convert(titles):\n",
    "    new_titles=[]\n",
    "    for i in range(len(titles)):\n",
    "        new_titles.append(title_convert(titles[i]))\n",
    "    return new_titles\n",
    "\n",
    "def combine_title_text(title, text):\n",
    "    out=[]\n",
    "    for i in range(len(text)):\n",
    "        out.append(title[i]+\" \"+text[i])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefixed_titles=mult_title_convert(title_no_stops)\n",
    "combined_text_title=combine_title_text(prefixed_titles, lower_text)\n",
    "# combined_text_title[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0: Feature Sets\n",
    "1. TFIDF of Text and Title\n",
    "2. TFIDF of Text\n",
    "3. TFIDF of Title\n",
    "4. TFIDF of Text and Title + Bigrams\n",
    "5. TFIDF of Text + Bigrams\n",
    "6. TFIDF of Title + Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: TFIDF Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_title = TfidfVectorizer(min_df=1,stop_words='english',max_features=100, lowercase=True)\n",
    "title_x_tfidf = tf_title.fit_transform(title_no_stops)\n",
    "title_x_tfidf_array = title_x_tfidf.toarray()\n",
    "# tf_title.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: TFIDF of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '200',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '21',\n",
       " '22',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '35',\n",
       " '40',\n",
       " '50',\n",
       " '500',\n",
       " '60',\n",
       " 'abedin',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abortion',\n",
       " 'absolutely',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accused',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activists',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'administration',\n",
       " 'advantage',\n",
       " 'adviser',\n",
       " 'affairs',\n",
       " 'afghanistan',\n",
       " 'african',\n",
       " 'age',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agents',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aides',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'al',\n",
       " 'aleppo',\n",
       " 'allies',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'alternative',\n",
       " 'amendment',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'analysis',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'answer',\n",
       " 'anti',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'approach',\n",
       " 'april',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'argued',\n",
       " 'argument',\n",
       " 'arizona',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arrested',\n",
       " 'article',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'assad',\n",
       " 'assault',\n",
       " 'associated',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attention',\n",
       " 'attorney',\n",
       " 'audience',\n",
       " 'august',\n",
       " 'author',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'available',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'backed',\n",
       " 'bad',\n",
       " 'ballot',\n",
       " 'ban',\n",
       " 'bank',\n",
       " 'banks',\n",
       " 'barack',\n",
       " 'base',\n",
       " 'based',\n",
       " 'battle',\n",
       " 'beat',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behavior',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believes',\n",
       " 'ben',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'benghazi',\n",
       " 'bernie',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bid',\n",
       " 'biden',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'billion',\n",
       " 'billionaire',\n",
       " 'bit',\n",
       " 'black',\n",
       " 'blame',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'blue',\n",
       " 'board',\n",
       " 'body',\n",
       " 'boehner',\n",
       " 'bomb',\n",
       " 'book',\n",
       " 'border',\n",
       " 'born',\n",
       " 'brain',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'bring',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'broke',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'budget',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'businesses',\n",
       " 'buy',\n",
       " 'california',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'came',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'campaigns',\n",
       " 'cancer',\n",
       " 'candidacy',\n",
       " 'candidate',\n",
       " 'candidates',\n",
       " 'capital',\n",
       " 'capitol',\n",
       " 'car',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carolina',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'carson',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'caucus',\n",
       " 'caucuses',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'center',\n",
       " 'central',\n",
       " 'century',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chairman',\n",
       " 'challenge',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charges',\n",
       " 'check',\n",
       " 'chicago',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'children',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'chris',\n",
       " 'christian',\n",
       " 'christians',\n",
       " 'christie',\n",
       " 'church',\n",
       " 'cia',\n",
       " 'cities',\n",
       " 'citizens',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'claim',\n",
       " 'claimed',\n",
       " 'claims',\n",
       " 'class',\n",
       " 'classified',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'cleveland',\n",
       " 'click',\n",
       " 'climate',\n",
       " 'clinton',\n",
       " 'clintons',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'cnn',\n",
       " 'coal',\n",
       " 'coalition',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comey',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'comments',\n",
       " 'committed',\n",
       " 'committee',\n",
       " 'common',\n",
       " 'communications',\n",
       " 'communities',\n",
       " 'community',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'compared',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerns',\n",
       " 'conducted',\n",
       " 'conference',\n",
       " 'confirmed',\n",
       " 'conflict',\n",
       " 'congress',\n",
       " 'congressional',\n",
       " 'consequences',\n",
       " 'conservative',\n",
       " 'conservatives',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'constitution',\n",
       " 'constitutional',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'contrast',\n",
       " 'contributed',\n",
       " 'control',\n",
       " 'controlled',\n",
       " 'controversial',\n",
       " 'convention',\n",
       " 'conversation',\n",
       " 'core',\n",
       " 'corporate',\n",
       " 'corrupt',\n",
       " 'corruption',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'couldn',\n",
       " 'council',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'county',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'court',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'create',\n",
       " 'created',\n",
       " 'credit',\n",
       " 'crime',\n",
       " 'crimes',\n",
       " 'criminal',\n",
       " 'crisis',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'critics',\n",
       " 'crowd',\n",
       " 'cruz',\n",
       " 'cuba',\n",
       " 'culture',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'cut',\n",
       " 'cuts',\n",
       " 'cycle',\n",
       " 'daily',\n",
       " 'dakota',\n",
       " 'damage',\n",
       " 'dangerous',\n",
       " 'data',\n",
       " 'daughter',\n",
       " 'david',\n",
       " 'davis',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'deals',\n",
       " 'death',\n",
       " 'debate',\n",
       " 'debates',\n",
       " 'debt',\n",
       " 'decade',\n",
       " 'decades',\n",
       " 'december',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'decisions',\n",
       " 'declared',\n",
       " 'declined',\n",
       " 'deep',\n",
       " 'deeply',\n",
       " 'defeat',\n",
       " 'defend',\n",
       " 'defense',\n",
       " 'delegate',\n",
       " 'delegates',\n",
       " 'demand',\n",
       " 'democracy',\n",
       " 'democrat',\n",
       " 'democratic',\n",
       " 'democrats',\n",
       " 'denied',\n",
       " 'department',\n",
       " 'described',\n",
       " 'designed',\n",
       " 'despite',\n",
       " 'details',\n",
       " 'development',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'died',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'director',\n",
       " 'discovered',\n",
       " 'discussion',\n",
       " 'district',\n",
       " 'dnc',\n",
       " 'documents',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'dollar',\n",
       " 'dollars',\n",
       " 'domestic',\n",
       " 'don',\n",
       " 'donald',\n",
       " 'donors',\n",
       " 'door',\n",
       " 'doubt',\n",
       " 'dr',\n",
       " 'drug',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'easy',\n",
       " 'economic',\n",
       " 'economy',\n",
       " 'editor',\n",
       " 'education',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effort',\n",
       " 'efforts',\n",
       " 'elected',\n",
       " 'election',\n",
       " 'elections',\n",
       " 'electoral',\n",
       " 'electorate',\n",
       " 'elite',\n",
       " 'elites',\n",
       " 'email',\n",
       " 'emails',\n",
       " 'employees',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'energy',\n",
       " 'enforcement',\n",
       " 'ensure',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'era',\n",
       " 'especially',\n",
       " 'essentially',\n",
       " 'establishment',\n",
       " 'estate',\n",
       " 'europe',\n",
       " 'european',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'events',\n",
       " 'eventually',\n",
       " 'everybody',\n",
       " 'evidence',\n",
       " 'evil',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'exchange',\n",
       " 'executive',\n",
       " 'expect',\n",
       " 'expected',\n",
       " 'experience',\n",
       " 'experts',\n",
       " 'explain',\n",
       " 'explained',\n",
       " 'expressed',\n",
       " 'extreme',\n",
       " 'extremely',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'facing',\n",
       " 'fact',\n",
       " 'facts',\n",
       " 'failed',\n",
       " 'failure',\n",
       " 'fair',\n",
       " 'faith',\n",
       " 'fall',\n",
       " 'false',\n",
       " 'familiar',\n",
       " 'families',\n",
       " 'family',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'father',\n",
       " 'favor',\n",
       " 'fbi',\n",
       " 'fear',\n",
       " 'february',\n",
       " 'fed',\n",
       " 'federal',\n",
       " 'feel',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'female',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'fighters',\n",
       " 'fighting',\n",
       " 'figure',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'financial',\n",
       " 'fiorina',\n",
       " 'fired',\n",
       " 'firm',\n",
       " 'floor',\n",
       " 'florida',\n",
       " 'focus',\n",
       " 'focused',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'food',\n",
       " 'force',\n",
       " 'forced',\n",
       " 'forces',\n",
       " 'foreign',\n",
       " 'form',\n",
       " 'forward',\n",
       " 'foundation',\n",
       " 'fox',\n",
       " 'france',\n",
       " 'fraud',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'french',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'fully',\n",
       " 'fund',\n",
       " 'funding',\n",
       " 'future',\n",
       " 'game',\n",
       " 'gas',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'general',\n",
       " 'generation',\n",
       " 'george',\n",
       " 'germany',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'global',\n",
       " 'goal',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gold',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'gop',\n",
       " 'got',\n",
       " 'gov',\n",
       " 'government',\n",
       " 'governments',\n",
       " 'governor',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'green',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'growing',\n",
       " 'growth',\n",
       " 'gun',\n",
       " 'guns',\n",
       " 'guy',\n",
       " 'half',\n",
       " 'hall',\n",
       " 'hampshire',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happens',\n",
       " 'hard',\n",
       " 'hasn',\n",
       " 'hate',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'head',\n",
       " 'health',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'hearing',\n",
       " 'heart',\n",
       " 'held',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'helping',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highest',\n",
       " 'highly',\n",
       " 'hill',\n",
       " 'hillary',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'holding',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'hopes',\n",
       " 'host',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'http',\n",
       " 'huge',\n",
       " 'human',\n",
       " 'hundreds',\n",
       " 'husband',\n",
       " 'idea',\n",
       " 'ideas',\n",
       " 'identified',\n",
       " 'ideological',\n",
       " 'illegal',\n",
       " 'image',\n",
       " 'imagine',\n",
       " 'immediately',\n",
       " 'immigrants',\n",
       " 'immigration',\n",
       " 'impact',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'incident',\n",
       " 'include',\n",
       " 'included',\n",
       " 'includes',\n",
       " 'including',\n",
       " 'income',\n",
       " 'increase',\n",
       " 'increased',\n",
       " 'increasingly',\n",
       " 'independent',\n",
       " 'india',\n",
       " 'indiana',\n",
       " 'individual',\n",
       " 'individuals',\n",
       " 'industry',\n",
       " 'influence',\n",
       " 'information',\n",
       " 'infowars',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'institute',\n",
       " 'insurance',\n",
       " 'intelligence',\n",
       " 'interests',\n",
       " 'internal',\n",
       " 'international',\n",
       " 'internet',\n",
       " 'interview',\n",
       " 'investigation',\n",
       " 'investigators',\n",
       " 'investment',\n",
       " 'involved',\n",
       " 'iowa',\n",
       " 'iran',\n",
       " 'iranian',\n",
       " 'iraq',\n",
       " 'iraqi',\n",
       " 'isis',\n",
       " 'islam',\n",
       " 'islamic',\n",
       " 'isn',\n",
       " 'israel',\n",
       " 'israeli',\n",
       " 'issue',\n",
       " 'issued',\n",
       " 'issues',\n",
       " 'james',\n",
       " 'january',\n",
       " 'jeb',\n",
       " 'jersey',\n",
       " 'jewish',\n",
       " 'jews',\n",
       " 'job',\n",
       " 'jobs',\n",
       " 'joe',\n",
       " 'john',\n",
       " 'johnson',\n",
       " 'join',\n",
       " 'joined',\n",
       " 'journal',\n",
       " 'journalists',\n",
       " 'judge',\n",
       " 'july',\n",
       " 'june',\n",
       " 'just',\n",
       " 'justice',\n",
       " 'kasich',\n",
       " 'keeping',\n",
       " 'kelly',\n",
       " 'kept',\n",
       " 'kerry',\n",
       " 'key',\n",
       " 'kids',\n",
       " 'kill',\n",
       " 'killed',\n",
       " 'killing',\n",
       " 'kind',\n",
       " 'king',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knowledge',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'labor',\n",
       " 'lack',\n",
       " 'land',\n",
       " 'language',\n",
       " 'large',\n",
       " 'largely',\n",
       " 'larger',\n",
       " 'largest',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'launched',\n",
       " 'law',\n",
       " 'lawmakers',\n",
       " 'laws',\n",
       " 'lead',\n",
       " 'leader',\n",
       " 'leaders',\n",
       " 'leadership',\n",
       " 'leading',\n",
       " 'leads',\n",
       " 'learn',\n",
       " 'learned',\n",
       " 'leave',\n",
       " 'leaving',\n",
       " 'led',\n",
       " 'left',\n",
       " 'legal',\n",
       " 'legislation',\n",
       " 'let',\n",
       " 'letter',\n",
       " 'level',\n",
       " 'levels',\n",
       " 'liberal',\n",
       " 'liberty',\n",
       " 'libya',\n",
       " 'lies',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'limited',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'link',\n",
       " 'list',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'living',\n",
       " 'll',\n",
       " 'local',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lose',\n",
       " 'losing',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lynch',\n",
       " 'magazine',\n",
       " 'mail',\n",
       " 'main',\n",
       " 'mainstream',\n",
       " 'major',\n",
       " 'majority',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'manager',\n",
       " 'march',\n",
       " 'marco',\n",
       " 'mark',\n",
       " 'market',\n",
       " 'marriage',\n",
       " 'mass',\n",
       " 'massive',\n",
       " 'material',\n",
       " 'matter',\n",
       " 'matters',\n",
       " 'maybe',\n",
       " 'mccain',\n",
       " 'mcconnell',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'meant',\n",
       " 'measure',\n",
       " 'media',\n",
       " 'medical',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'member',\n",
       " 'members',\n",
       " 'men',\n",
       " 'message',\n",
       " 'met',\n",
       " 'mexico',\n",
       " 'michael',\n",
       " 'michigan',\n",
       " 'middle',\n",
       " 'mike',\n",
       " 'miles',\n",
       " 'militants',\n",
       " 'military',\n",
       " 'million',\n",
       " 'millions',\n",
       " 'mind',\n",
       " 'minister',\n",
       " 'minority',\n",
       " 'minutes',\n",
       " 'mission',\n",
       " 'mitt',\n",
       " 'moderate',\n",
       " 'modern',\n",
       " 'moment',\n",
       " 'monday',\n",
       " 'money',\n",
       " 'month',\n",
       " 'months',\n",
       " 'moral',\n",
       " 'morning',\n",
       " 'moscow',\n",
       " 'mosul',\n",
       " 'mother',\n",
       " 'moved',\n",
       " 'movement',\n",
       " 'moving',\n",
       " 'mr',\n",
       " 'multiple',\n",
       " 'murder',\n",
       " 'muslim',\n",
       " 'muslims',\n",
       " 'named',\n",
       " 'nation',\n",
       " 'national',\n",
       " 'nations',\n",
       " 'native',\n",
       " 'nato',\n",
       " 'natural',\n",
       " 'nature',\n",
       " 'nbc',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needs',\n",
       " 'negative',\n",
       " 'negotiations',\n",
       " 'netanyahu',\n",
       " 'network',\n",
       " 'nevada',\n",
       " 'new',\n",
       " 'news',\n",
       " 'night',\n",
       " 'nomination',\n",
       " 'nominee',\n",
       " 'non',\n",
       " 'north',\n",
       " 'note',\n",
       " 'noted',\n",
       " 'notes',\n",
       " 'november',\n",
       " 'nuclear',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'obama',\n",
       " 'obamacare',\n",
       " 'obvious',\n",
       " 'obviously',\n",
       " 'oct',\n",
       " 'october',\n",
       " 'offer',\n",
       " 'offered',\n",
       " 'office',\n",
       " 'officer',\n",
       " 'officers',\n",
       " 'official',\n",
       " 'officials',\n",
       " 'ohio',\n",
       " 'oil',\n",
       " 'old',\n",
       " 'ones',\n",
       " 'ongoing',\n",
       " 'online',\n",
       " 'open',\n",
       " 'operation',\n",
       " 'operations',\n",
       " 'opinion',\n",
       " 'opponents',\n",
       " 'opportunity',\n",
       " 'opposed',\n",
       " 'opposition',\n",
       " 'order',\n",
       " 'organization',\n",
       " 'organizations',\n",
       " 'outcome',\n",
       " 'outside',\n",
       " 'overall',\n",
       " 'pac',\n",
       " 'page',\n",
       " 'paid',\n",
       " 'palestinian',\n",
       " 'paper',\n",
       " 'parents',\n",
       " 'paris',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'parties',\n",
       " 'partisan',\n",
       " 'partners',\n",
       " 'parts',\n",
       " 'party',\n",
       " 'pass',\n",
       " 'passed',\n",
       " 'past',\n",
       " 'path',\n",
       " 'paul',\n",
       " 'pay',\n",
       " 'peace',\n",
       " 'pence',\n",
       " 'pennsylvania',\n",
       " 'pentagon',\n",
       " 'people',\n",
       " 'percent',\n",
       " 'percentage',\n",
       " 'period',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'phone',\n",
       " 'photo',\n",
       " 'pick',\n",
       " 'piece',\n",
       " 'pipeline',\n",
       " 'place',\n",
       " 'places',\n",
       " 'plan',\n",
       " 'plane',\n",
       " 'planet',\n",
       " 'planned',\n",
       " 'plans',\n",
       " 'platform',\n",
       " 'play',\n",
       " 'played',\n",
       " 'playing',\n",
       " 'plus',\n",
       " 'podesta',\n",
       " 'point',\n",
       " 'pointed',\n",
       " 'points',\n",
       " ...]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_text = TfidfVectorizer(min_df=1,stop_words='english',max_features=1500, lowercase=True)\n",
    "text_x_tfidf = tf_text.fit_transform(lower_text)\n",
    "text_x_tfidf_array = text_x_tfidf.toarray()\n",
    "tf_text.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 TFIDF of Title and Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_combined = TfidfVectorizer(min_df=1,stop_words='english',max_features=2000, lowercase=True)\n",
    "combined_tfidf = tf_combined.fit_transform(combined_text_title)\n",
    "combined_tfidf_array = combined_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 TFIDF  Combined Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined= np.hstack((title_x_tfidf_array, text_x_tfidf_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##video feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_feature_set= has_video_feature_set(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_feature_set_arr= np.asarray(video_feature_set).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4: Models and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder of variables:\n",
    "y: stores converted labels\n",
    "combined_tfidf_array: stores feature array of tfidf of titles and text\n",
    "title_x_tfidf_array\n",
    "text_x_tfidf_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0: Cross Validate Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "name: avg_cross_val\n",
    "in: \n",
    "    classifier (object that implements fit)\n",
    "    x (features)\n",
    "    y (labels)\n",
    "    cv (either number of desired folds or cross validation object)\n",
    "out: returns average score from array of scores from cross_val_score\n",
    "\"\"\"\n",
    "def cross_val(classifier, x, y, cv):\n",
    "    return np.mean(cross_val_score(classifier, x, y, cv=cv))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1: TFIDF of Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6632931649088738"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb1= MultinomialNB(alpha=1)\n",
    "cross_val(mnb1, title_x_tfidf_array, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2: TFIDF of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85619072351704395"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb2= MultinomialNB(alpha=1)\n",
    "cross_val(mnb2, text_x_tfidf_array, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 TFIDF of Text and Titles Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86376967665173687"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb3= MultinomialNB(alpha=1)\n",
    "cross_val(mnb3, combined_tfidf_array, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4: testing out trying to combine two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85256146742103966"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb4= MultinomialNB(alpha=1)\n",
    "cross_val(mnb4, combined, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### video feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50055267380676938"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb5= MultinomialNB(alpha=1)\n",
    "cross_val(mnb5, np.asarray(video_feature_set_arr), y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAndom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1: TFIDF of Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69644833706489817"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest1 = RandomForestClassifier(max_depth=10,n_estimators=100,min_samples_leaf=2)\n",
    "cross_val(forest1, title_x_tfidf_array, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2: TFIDF of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87135211747222674"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2 = RandomForestClassifier(max_depth=10,n_estimators=100,min_samples_leaf=2)\n",
    "cross_val(forest2, text_x_tfidf_array, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 TFIDF of Text and Titles Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87292791026444994"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest3 = RandomForestClassifier(max_depth=10,n_estimators=100,min_samples_leaf=2)\n",
    "cross_val(forest3, combined_tfidf_array, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.4: testing out trying to combine two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87087818303812981"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest4 = RandomForestClassifier(max_depth=10,n_estimators=100,min_samples_leaf=2)\n",
    "cross_val(forest4, combined, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIDEAS:\\nput all feature sets in an array\\nmake a features method that takes in diff tuning parameters\\nmake a method that takes in a model and tests it on different featuresets and diff parameters and prints results in chart\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "IDEAS:\n",
    "put all feature sets in an array\n",
    "make a features method that takes in diff tuning parameters\n",
    "make a method that takes in a model and tests it on different featuresets and diff parameters and prints results in chart\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.5: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1TFIDF of Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72738436632284631"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm1 = SVC(gamma='auto')\n",
    "cross_val(svm1, title_x_tfidf_array, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 TFIDF of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50055267380676938"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2=SVC(gamma='auto')\n",
    "cross_val(svm2, text_x_tfidf_array, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 TFIDF of Text and Titles Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm3=SVC(gamma='auto')\n",
    "cross_val(svm3, combined_tfidf_array, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.4 TFIDF Combined Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm4=SVC(gamma='auto')\n",
    "cross_val(svm4, combined, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
